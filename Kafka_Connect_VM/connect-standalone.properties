# /opt/kafka/config/connect-standalone.properties# 커넥터 이름
name=s3-sink-connector

# S3 Sink Connector 클래스
connector.class=io.confluent.connect.s3.S3SinkConnector

# 태스크 개수
tasks.max=1

# 연결할 토픽 (쉼표로 여러 개 가능)
topics=nginx-logs

# Object Storage/S3 설정
s3.region=kr-central-2
s3.bucket.name={버킷 이름}
s3.part.size=5242880

aws.access.key.id={S3_ACCESS_KEY}
aws.secret.access.key={S3_SECRET_ACCESS_KEY}
store.url=https://objectstorage.kr-central-2.kakaocloud.com

# Key/Value Converter
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=false
value.converter.schemas.enable=false

# Offset 관련 파일 경로(standalone 모드에서 필수)
offset.storage.file.filename=/tmp/connect.offsets

# 카프카 브로커 정보
bootstrap.servers={kafka 부트스트랩 서버}

# 플러그인 경로
plugin.path=/confluent-hub/plugins

# 커넥트 HTTP 리스너 (standalone 테스트 시 0.0.0.0:8083 로 열 수도 있음)
listeners=http://0.0.0.0:8083

# 스토리지/포맷
storage.class=io.confluent.connect.s3.storage.S3Storage
format.class=io.confluent.connect.s3.format.json.JsonFormat

# flush.size: 파일이 쌓인 뒤 S3에 실제 업로드되는 기준
flush.size=1
