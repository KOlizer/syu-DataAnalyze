# 콘솔에서 리소스 생성 및 연동

## 1. 카탈로그 생성
- 이름:`data_catalog`
- vpc: `실습 환경`
- 서브넷: `실습 환경`
</br>

## 2. 데이터베이스 생성
1. 콘솔에서 생성한 카탈로그 클릭
2. `데이터 베이스 생성` 클릭
3. 생성 정보
   - 카탈로그: `data_catalog`
   - 이름: `database`
   - 경로
     - 버킷 이름:{카프카로 만든 버킷}
     - 디렉터리:{obj-kafka/2025/02/05} // 현재 임의 설정
</br>

## 3. 데이터베이스 생성
1. 콘솔에서 생성한 데이터베이스 클릭
2. `테이블 생성` 클릭
3. 생성 정보
   - 테이블 이름: `data_table`
   - 데이터 저장경로
     - 버킷 이름: {카프카로 만든 버킷}
     - 디렉터리: {test/01} // 임의로 테스트
   - 데이터 유형: `JSON` // 테스트
   - Pub/Sub 연동: `사용` // 테스트
     - 토픽 선택: {data-catalog-topic}
     - `저장` 클릭
   - 스키마(추후 시나리오에 맞게 수정해야함)
     - `필드추가` 클릭
     - `파티션 키`: 사용
     - 필드 이름: `partition_key`
     - 데이터 유형: `string
     - ---
    
     - `필드추가` 클릭
     - `파티션 키`: 미사용
     - 필드 이름: `id`
     - 데이터 유형: `int`
     - ---
    
     - `필드추가` 클릭
     - `파티션 키`: 미사용
     - 필드 이름: `name`
     - 데이터 유형: `string`
    
   - 모든 필드 선택 후 `생성` 클릭



## 4. Hadoop 생성
   1. 콘솔에서 Analytics -> Hadoop Eco -> 클러스터 접속
   2. `클러스터 생성` 클릭
   3. 클러스터 정보
      - 클러스터 이름: `core-hadoop-cluster`
      - 클러스터 구성: `Core Hadoop`
      - 관리자 설정
        - 관리자 아이디: admin
        - 관리자 비밀번호: Admin1234!
      - vpc: `실습 환경`
      - 서브넷: `실습 환경`
      - 보안 그룹: `그대로`
      - `다음` 클릭
      - ---
      - 마스터 노드 설정
        - 인스턴스 유형: `m2a.xlarge`
          
      - 워커 노드 설정
        - 인스턴스 개수: 2
        - 인스턴스 유형: `m2a.xlarge`
       
      - `다음` 클릭

## 5. 크롤러

